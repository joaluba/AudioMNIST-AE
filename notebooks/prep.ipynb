{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3243096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ubuntu/joanna/AudioMNIST-AE/src/')\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "# my modules:\n",
    "import helpers\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "importlib.reload(helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1389f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing (wav -> power spectrogram):\n",
    "sig_orig,S,minmax=helpers.wav2powspec(\"test.wav\")\n",
    "\n",
    "# plot original and reconstructed signal\n",
    "helpers.plot_spectrogram(S, title=None, ylabel=\"freq_bin\")\n",
    "\n",
    "# Post-processing (power spectrogram -> wav):\n",
    "sig_recon=helpers.powspec2wave(S,orig_min=minmax[\"min\"],orig_max=minmax[\"max\"])\n",
    "\n",
    "# plot original and reconstructed signal\n",
    "plt.figure()\n",
    "plt.plot(sig_orig,label='original')\n",
    "plt.plot(sig_recon,label='Griffin-Lim reconstruction')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# check how the reconstruction sounds\n",
    "sf.write('test_reconstructed.wav', sig_recon.numpy().T, 22050, subtype='PCM_24')\n",
    "Audio('test_reconstructed.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my module with data loader which uses these preprocessing steps \n",
    "import torchdataset_prep as dsprep\n",
    "importlib.reload(dsprep)\n",
    "\n",
    "# Parameters of data loader\n",
    "AUDIO_PATH = \"/home/ubuntu/Data/AudioMNIST/data\"\n",
    "SAMPLE_RATE = 22050\n",
    "SIG_LEN=1\n",
    "SNR=100\n",
    "N_SPK=60\n",
    "\n",
    "# Parameters of data loader\n",
    "dataset = dsprep.AudioMnistPowSpec(AUDIO_PATH, SAMPLE_RATE, SIG_LEN,N_SPK,SNR)\n",
    "random_idx=np.random.randint(1,len(dataset))\n",
    "data, label = dataset[random_idx]\n",
    "# plot a random data point\n",
    "helpers.plot_datapoint(data,label)\n",
    "sig_recon=helpers.powspec2wave(data,orig_min=0,orig_max=5)\n",
    "sf.write('reconstructed.wav', sig_recon.numpy().T, 22050, subtype='PCM_24')\n",
    "Audio('reconstructed.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4580bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my module with model definition and training procedure\n",
    "import training as TR\n",
    "importlib.reload(TR)\n",
    "\n",
    "# choose computing device\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"Using M1\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using Cuda\")\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "# split dataset into training set, test set and validation set\n",
    "N_train = round(len(dataset) * 0.8)\n",
    "N_rest = len(dataset) - N_train\n",
    "trainset, restset = torch.utils.data.random_split(dataset, [N_train, N_rest])\n",
    "N_test = round(len(restset) * 0.5)\n",
    "N_val = len(restset) - N_test\n",
    "testset, valset = torch.utils.data.random_split(restset, [N_test, N_val])\n",
    "\n",
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=6)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=True, num_workers=6)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True, num_workers=6)\n",
    "    \n",
    "# instantiate a model\n",
    "model=TR.AutoencoderConv()\n",
    "model.to(device)\n",
    "\n",
    "# training\n",
    "N_EPOCHS=30\n",
    "outputs=TR.training(model, trainloader, N_EPOCHS, device,store_outputs=True)\n",
    "\n",
    "# save model\n",
    "now=datetime.now(); dt_string = now.strftime(\"%d-%m-%Y--%H-%M\")\n",
    "torch.save(model.state_dict(), \"../models/trained_model_\"+dt_string+\".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = print the reconstruction\n",
    "n_examples=5\n",
    "for i in range(0,9):\n",
    "    fig, axs = plt.subplots(2,n_examples)\n",
    "    x_orig=outputs[i][1]\n",
    "    x_recon=outputs[i][2]\n",
    "    x_label=outputs[i][3]\n",
    "    for k in range(0,n_examples):\n",
    "        x_orig_plot=torch.squeeze(x_orig[k].reshape(-1,513,44).detach()).cpu()\n",
    "        x_recon_plot=torch.squeeze(x_recon[k].reshape(-1,513,44).detach()).cpu()\n",
    "        x_label_plot=torch.squeeze(x_label[k].detach()).cpu()\n",
    "        \n",
    "        axs[0,k].set_title(\"orig \"+ str(x_label_plot))\n",
    "        axs[0,k].imshow(librosa.power_to_db(x_orig_plot), origin=\"lower\", aspect=\"auto\")\n",
    "        \n",
    "        axs[1,k].set_title(\"recon \"+ str(x_label_plot))\n",
    "        axs[1,k].imshow(librosa.power_to_db(x_recon_plot), origin=\"lower\", aspect=\"auto\")\n",
    "\n",
    "        \n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how good is the reconstruction\n",
    "FINAL_EPOCH=9\n",
    "x_recon=outputs[FINAL_EPOCH][2]\n",
    "x_label=outputs[FINAL_EPOCH][3]\n",
    "rand_idx=np.random.randint(1,48)\n",
    "x_recon_play=torch.squeeze(x_recon[rand_idx].reshape(-1,513,44).detach()).cpu()\n",
    "x_label_play=torch.squeeze(x_label[rand_idx].detach()).cpu()\n",
    "sig_recon=helpers.powspec2wave(x_recon_play,orig_min=0,orig_max=5)\n",
    "sf.write('reconstructed.wav', sig_recon.numpy().T, 22050, subtype='PCM_24')\n",
    "\n",
    "\n",
    "print(\"Original label: \"+ str(x_label_play.numpy()))\n",
    "Audio('reconstructed.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dcf8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1,16,3,2,1\n",
    "O1=helpers.compute_cnn_out([1,513,44,1],[16,3,3,1],[1,1],[2,2])\n",
    "print(O1)\n",
    "O2=helpers.compute_cnn_out([1, 257.0, 22.0, 16],[32,3,3,16],[1,1],[2,2])\n",
    "print(O2)\n",
    "O3=helpers.compute_cnn_out([1, 129.0, 11.0, 32],[64,129,11,32],[0,0],[1,1])\n",
    "print(O3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae82144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
